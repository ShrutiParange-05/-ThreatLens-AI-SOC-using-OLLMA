# ðŸ›¡ï¸ ThreatLens: AI-Powered SOC Analyst Platform

**ThreatLens** is a local, privacy-first Security Operations Center (SOC) dashboard. It integrates real-time threat monitoring with a **Local LLM (Llama 3)** to simulate, detect, and analyze cyberattacks without data leaving the secure environment.


## ðŸš€ Key Features

### 1. ðŸ§  Autonomous AI Analyst
- **Local LLM Integration:** Uses **Ollama (Llama 3)** for offline analysis.
- **RAG (Retrieval-Augmented Generation):** Upload security policies (PDF) for context-aware answers.
- **Privacy Guard:** Middleware layer that redacts PII (IPs, Emails) *before* inference.

### 2. ðŸ”´ Red Team Simulator (BAS)
- **Breach & Attack Simulation:** Launch simulated attacks (SQL Injection, DDoS, Ransomware) directly from the UI.
- **Auto-Detection:** The AI Analyst automatically triggers to investigate simulated breaches.

### 3. ðŸ“Š Live Threat Intelligence
- **3D Attack Map:** Visualizes threat origins using weighted geopolitical data.
- **Real-time Logs:** Monitors network traffic and endpoint security events.

## ðŸ› ï¸ Tech Stack
- **Frontend:** Streamlit (Python)
- **AI/ML:** LangChain, Ollama, FAISS (Vector DB)
- **Visualization:** PyDeck, Plotly
- **Reporting:** FPDF (Automated Incident Reports)

## âš™ï¸ Installation

1. **Prerequisites:**
   - Install [Ollama](https://ollama.com/)
   - Pull the model: `ollama pull llama3`

2. **Clone the Repo:**
https://github.com/ShrutiParange-05/-ThreatLens-AI-SOC-using-OLLMA
## ðŸ›¡ï¸ Security Validation & Red Teaming

To ensure robustness, I performed an adversarial assessment (Red Teaming) against the ThreatLens AI to identify vulnerabilities in the LLM's safety alignment.

### 1. âœ… Privacy Guard Success
**Test:** Attempted to trick the AI into leaking a user's IP address and password using a "Repeat back to me" prompt.
**Result:** **Blocked.** The `PrivacyGuard` middleware successfully detected the PII pattern and redacted the sensitive data before it reached the model.
> `ðŸš¨ BLOCKED: AI attempted to leak redacted info.`
> <img width="1205" height="405" alt="image" src="https://github.com/user-attachments/assets/157016c4-e611-4c62-95b1-203a6b4ea118" />


### 2. âš ï¸ Role-Playing Jailbreak (Finding)
**Test:** Attempted to bypass safety filters by framing a request for an SQL Injection payload as "Educational Material" for a "Cybersecurity Professor."
**Result:** **Successful Bypass.** The model prioritized the "Helpful" instruction over its safety training.

**Evidence:**
> <img width="1372" height="542" alt="image" src="https://github.com/user-attachments/assets/8d89e820-f165-4c1f-9e0c-667fd7a2cff0" />

### ðŸ”® Future Mitigation Roadmap
To address the role-playing vulnerability, the next version of ThreatLens will implement:
1.  **Semantic Intent Analysis:** Using **NVIDIA NeMo Guardrails** to classify the *intent* of a prompt (e.g., "Malicious Code Generation") regardless of the user's framing.
2.  **Output Filtering:** A secondary "Judge" model to review the AI's response for dangerous keywords (e.g., `UNION SELECT`, `DROP TABLE`) before showing it to the user.

